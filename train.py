# train.py

import os
import torch
import torch.nn as nn

from config import cfg
# from dataset import prepare_dataloaders
from models.unet2d import UNet

# from models import build_model_from_cfg
import time
import numpy as np
from dataset import prepare_dataloaders, load_numpy_for_coregan
from models import build_model_from_cfg, CoreGANGenerator, CoreGANDiscriminator

from models.coregan_pytorch import (
    CoreGANGenerator,
    CoreGANDiscriminator,
    CoreGANConfig,
    CoreGANTrainer,
)


def feature_matching_l2_sq(f_real: torch.Tensor, f_fake: torch.Tensor) -> torch.Tensor:
    """
    Eq (4): || f_real - f_fake ||_2^2 averaged over batch.
    f_*: (B, F)
    """
    diff = f_real - f_fake
    return (diff.pow(2).sum(dim=1)).mean()   # mean over batch of squared L2

def set_requires_grad(net, flag: bool):
    for p in net.parameters():
        p.requires_grad = flag

def _build_sequences_np(X, Y, K):
    """
    Build sequences of length K from single windows.

    X: (N, C, H, W)
    Y: (N, H_out, W_out) or (N, C_out, H_out, W_out)

    Returns:
      X_seq: (N_seq, K, C, H, W)
      Y_seq: (N_seq, H_out, W_out) or (N_seq, C_out, H_out, W_out)
    """
    X = np.asarray(X)
    Y = np.asarray(Y)
    N = X.shape[0]
    assert N == Y.shape[0]

    if N < K:
        raise ValueError(f"Not enough windows ({N}) to build sequences with K={K}")

    X_seq_list = []
    Y_seq_list = []

    for t in range(K - 1, N):
        X_seq_list.append(X[t - K + 1 : t + 1])  # (K, C, H, W)
        Y_seq_list.append(Y[t])

    X_seq = np.stack(X_seq_list, axis=0)
    Y_seq = np.stack(Y_seq_list, axis=0)
    return X_seq, Y_seq

def _ensure_sequences_for_coregan(X, Y, K):
    """
    Normalize data to sequences for CoreGAN:

    Input:
      X: either
         - (N, K, C, H, W)  (already sequences)
         - (N, C, H, W)     (windows, we will build sequences)
         - (N, H, W)        (windows, we will add channel and build sequences)
      Y: either
         - (N, H_out, W_out)
         - (N, 1, H_out, W_out)
         - (N, K, ...) SHOULD NOT happen for CoreGAN

    Output:
      X_seq: (N_seq, K, 1, H, W)
      Y_seq: (N_seq, 1, H_out, W_out)
    """
    X = np.asarray(X)
    Y = np.asarray(Y)

    # --- Case 1: X already sequences: (N, K, C, H, W) ---
    if X.ndim == 5 and X.shape[1] == K:
        # Ensure channel dimension is present
        # X: (N, K, C, H, W)
        if X.shape[2] != cfg.in_channels:
            raise ValueError(f"[CoreGAN] Unexpected channel dim in X: {X.shape}")

        X_seq = X

        # Y can be (N, H_out, W_out) or (N, 1, H_out, W_out)
        if Y.ndim == 3:
            Y_seq = Y[:, None, :, :]
        elif Y.ndim == 4:
            Y_seq = Y
        else:
            raise ValueError(f"[CoreGAN] Unexpected Y shape (already-seq case): {Y.shape}")

        return X_seq, Y_seq

    # --- Case 2: X are windows: (N, C, H, W) or (N, H, W) ---
    # Ensure X has channel dim
    if X.ndim == 3:
        # (N, H, W) -> (N, 1, H, W)
        X = X[:, None, :, :]
    elif X.ndim == 4:
        # (N, C, H, W) as is
        pass
    else:
        raise ValueError(f"[CoreGAN] Unexpected X shape (windows case): {X.shape}")

    # Ensure Y is (N, H_out, W_out)
    if Y.ndim == 4 and Y.shape[1] == 1:
        # (N, 1, H_out, W_out) -> (N, H_out, W_out) for building sequences
        Y_win = Y[:, 0]
    elif Y.ndim == 3:
        Y_win = Y
    else:
        raise ValueError(f"[CoreGAN] Unexpected Y shape (windows case): {Y.shape}")

    X_seq, Y_seq = _build_sequences_np(X, Y_win, K)
    # X_seq: (N_seq, K, C, H, W)
    # Y_seq: (N_seq, H_out, W_out)

    # Add channel dim back to Y_seq
    Y_seq = Y_seq[:, None, :, :]
    return X_seq, Y_seq

def train_coregan():
    """
    CoreGAN training with:
      - image MSE
      - adversarial loss (BCE on probabilities from D)
      - feature-matching loss
      - optional extra fact-matching steps (pure image MSE).

    Uses the dataset generated by dataset.py (.npz) via load_numpy_for_coregan().
    """
    device = cfg.device
    if not torch.cuda.is_available():
        device = "cpu"
    print(f"[CoreGAN] Using device: {device}")

    # ---------- 1) Load numpy arrays from .npz ----------
    X_train, Y_train, X_val, Y_val, X_test, Y_test = load_numpy_for_coregan()
    print("[CoreGAN] Raw arrays from .npz:")
    print("  X_train:", X_train.shape)
    print("  Y_train:", Y_train.shape)
    print("  X_val  :", X_val.shape)
    print("  Y_val  :", Y_val.shape)
    print("  X_test :", X_test.shape)
    print("  Y_test :", Y_test.shape)

    K = cfg.context_len

    # Normalize shapes to sequences: (N, K, C, H, W) / (N, 1, H, W)
    X_train_seq, Y_train_seq = _ensure_sequences_for_coregan(X_train, Y_train, K)
    X_val_seq,   Y_val_seq   = _ensure_sequences_for_coregan(X_val,   Y_val,   K)
    X_test_seq,  Y_test_seq  = _ensure_sequences_for_coregan(X_test,  Y_test,  K)

    print("[CoreGAN] After building/ensuring sequences:")
    print("  X_train_seq:", X_train_seq.shape)
    print("  Y_train_seq:", Y_train_seq.shape)
    print("  X_val_seq  :", X_val_seq.shape)
    print("  Y_val_seq  :", Y_val_seq.shape)
    print("  X_test_seq :", X_test_seq.shape)
    print("  Y_test_seq :", Y_test_seq.shape)

    # Convert to torch tensors
    x_train_t = torch.from_numpy(X_train_seq).float()
    y_train_t = torch.from_numpy(Y_train_seq).float()
    x_val_t   = torch.from_numpy(X_val_seq).float()
    y_val_t   = torch.from_numpy(Y_val_seq).float()
    x_test_t  = torch.from_numpy(X_test_seq).float()
    y_test_t  = torch.from_numpy(Y_test_seq).float()

    print("[CoreGAN] Torch tensor shapes:")
    print("  x_train_t:", x_train_t.shape)
    print("  y_train_t:", y_train_t.shape)
    print("  x_val_t  :", x_val_t.shape)
    print("  y_val_t  :", y_val_t.shape)
    print("  x_test_t :", x_test_t.shape)
    print("  y_test_t :", y_test_t.shape)

    # ---------- 2) Build models ----------
    G = CoreGANGenerator(
        time_steps=cfg.context_len,
        in_channels=cfg.in_channels,
        H=cfg.H_out,
        W=cfg.W_out,
    ).to(device)

    D = CoreGANDiscriminator(
        in_channels=cfg.in_channels,
    ).to(device)

    # ---------- 3) Optimizers & losses ----------
    optimizer_G = torch.optim.RMSprop(G.parameters(), lr=5e-4)
    optimizer_D = torch.optim.RMSprop(D.parameters(), lr=5e-4)

    # IMPORTANT: use BCELoss (NOT BCEWithLogitsLoss) because D outputs sigmoid probabilities
    bce = nn.BCELoss()
    mse = nn.MSELoss()


    fact_matching_cnt = getattr(cfg, "gan_fact_matching_cnt", 1)
    lam_img = getattr(cfg, "gan_lambda_img", 1.0)
    lam_adv = getattr(cfg, "gan_lambda_adv", 1.0)
    lam_fm  = getattr(cfg, "gan_lambda_fm", 1.0)

    BATCH_SIZE = cfg.batch_size
    num_epochs = cfg.num_epochs

    # Early stopping
    best_val_loss = float("inf")
    patience = getattr(cfg, "early_stop_patience", 0)
    min_delta = getattr(cfg, "early_stop_min_delta", 0.0)
    no_improve_epochs = 0

    # Logging
    g_loss_ary = []
    d_loss_ary = []
    fm_loss_ary = []
    ff_loss_ary = []

    valid_label = 1.0
    fake_label  = 0.0

    N_train = x_train_t.size(0)
    N_val   = x_val_t.size(0)

    os.makedirs(cfg.checkpoint_dir, exist_ok=True)
    os.makedirs(cfg.results_dir, exist_ok=True)

    print(f"[CoreGAN] Training: N_train={N_train}, N_val={N_val}, epochs={num_epochs}")
    start_train_time = time.time()

    for epoch in range(1, num_epochs + 1):
        G.train()
        D.train()

        # shuffle training data
        perm = torch.randperm(N_train)
        x_train_t = x_train_t[perm]
        y_train_t = y_train_t[perm]

        epoch_g_losses = []
        epoch_d_losses = []
        epoch_fm_losses = []
        epoch_ff_losses = []

        # ----- epoch loop -----
        for start in range(0, N_train, BATCH_SIZE):
            end = min(start + BATCH_SIZE, N_train)
            if end - start < BATCH_SIZE:
                # drop incomplete batch
                continue

            x_batch = x_train_t[start:end].to(device)  # (B, K, C, H, W)
            y_batch = y_train_t[start:end].to(device)  # (B, 1, H, W)

            # ------------------ Train D ------------------
            with torch.no_grad():
                fake_imgs = G(x_batch)  # (B, 1, H, W)

            real_valid, _ = D(y_batch)    # probabilities in [0,1]
            fake_valid, _ = D(fake_imgs)

            valid = torch.full_like(real_valid, valid_label, device=device)
            fake  = torch.full_like(fake_valid, fake_label, device=device)

            d_loss_real = bce(real_valid, valid)
            d_loss_fake = bce(fake_valid, fake)
            d_loss = 0.5 * (d_loss_real + d_loss_fake)

            optimizer_D.zero_grad()
            d_loss.backward()
            optimizer_D.step()

            # ------------------ Train G ------------------
            fake_imgs = G(x_batch)
            fake_valid, feat_fake = D(fake_imgs)
            _, feat_real = D(y_batch)

            img_mse_loss = mse(fake_imgs, y_batch)              # reconstruction
            valid_for_g = torch.full_like(fake_valid, valid_label, device=device)
            gan_loss = bce(fake_valid, valid_for_g)             # adversarial
            fm_loss = mse(feat_fake, feat_real)                 # feature matching

            # g_loss = lam_img * img_mse_loss + lam_adv * gan_loss + lam_fm * fm_loss
            g_loss = lam_adv * gan_loss + lam_fm * fm_loss

            optimizer_G.zero_grad()
            g_loss.backward()
            optimizer_G.step()

            # extra fact matching steps (image MSE only)
            for _ in range(max(fact_matching_cnt - 1, 0)):
                fake_imgs = G(x_batch)
                fm_img_loss = mse(fake_imgs, y_batch)
                optimizer_G.zero_grad()
                fm_img_loss.backward()
                optimizer_G.step()

            epoch_g_losses.append(g_loss.item())
            epoch_d_losses.append(d_loss.item())
            epoch_fm_losses.append(fm_loss.item())
            epoch_ff_losses.append(gan_loss.item())

        # epoch means
        g_loss_epoch  = float(np.mean(epoch_g_losses))
        d_loss_epoch  = float(np.mean(epoch_d_losses))
        fm_loss_epoch = float(np.mean(epoch_fm_losses))
        ff_loss_epoch = float(np.mean(epoch_ff_losses))

        g_loss_ary.append(g_loss_epoch)
        d_loss_ary.append(d_loss_epoch)
        fm_loss_ary.append(fm_loss_epoch)
        ff_loss_ary.append(ff_loss_epoch)

        # ---------- validation MSE ----------
        G.eval()
        val_losses = []
        with torch.no_grad():
            for start in range(0, N_val, BATCH_SIZE):
                end = min(start + BATCH_SIZE, N_val)
                x_batch = x_val_t[start:end].to(device)
                y_batch = y_val_t[start:end].to(device)
                if x_batch.size(0) == 0:
                    continue
                pred = G(x_batch)
                val_losses.append(mse(pred, y_batch).item())

        val_loss = float(np.mean(val_losses)) if val_losses else float("inf")

        print(
            f"[CoreGAN] Epoch [{epoch}/{num_epochs}] "
            f"G={g_loss_epoch:.6f}, D={d_loss_epoch:.6f}, "
            f"FM={fm_loss_epoch:.6f}, FF={ff_loss_epoch:.6f}, "
            f"Val MSE={val_loss:.6f}"
        )

        # ---------- early stopping + checkpoint ----------
        if val_loss + min_delta < best_val_loss:
            best_val_loss = val_loss
            no_improve_epochs = 0
            torch.save(
                {
                    "model_state_dict": G.state_dict(),
                    "best_val_loss": best_val_loss,
                },
                cfg.model_ckpt,
            )
            print(f"  -> [CoreGAN] Saved best G to {cfg.model_ckpt}")
        else:
            no_improve_epochs += 1
            if patience > 0 and no_improve_epochs >= patience:
                print(
                    f"[CoreGAN] Early stopping at epoch {epoch} "
                    f"(no improvement for {patience} epochs)."
                )
                break

    end_train_time = time.time()
    print(f"[CoreGAN] Total training time: {end_train_time - start_train_time:.1f} s")

    # (Optional) you can add a test MSE loop here, similar to your previous script,
    # or rely on test.py for full reconstruction + visualization.



def train_one_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0.0

    for X_seq, Y in loader:
        X_seq = X_seq.to(device) # (B, K, 1, H_in, W_in)
        Y = Y.to(device)

        pred = model(X_seq)
        loss = criterion(pred, Y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(loader)


def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0

    with torch.no_grad():
        for X, Y in loader:
            X = X.to(device)
            Y = Y.to(device)

            pred = model(X)
            loss = criterion(pred, Y)
            total_loss += loss.item()

    return total_loss / len(loader)


def main():
    # if cfg.model_type.lower() == "coregan":
    #     # Use the GAN-specific training loop
    #     train_coregan()
    #     return

    device = cfg.device
    if not torch.cuda.is_available():
        device = "cpu"
    print(f"Using device: {device}")

    print("Preparing dataloaders (this will generate dataset if missing)...")
    train_loader, val_loader, test_loader, scaler, train_idx, val_idx, test_idx = prepare_dataloaders()

    n_train = len(train_idx)
    n_val = len(val_idx)
    print(f"Train windows: {n_train}, Val windows: {n_val}")
    print(f"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}")
    # -----------------------------
    # Branch for CoreGAN vs others
    # -----------------------------
    if cfg.model_type.lower() == "coregan":
        # --- CoreGAN training using the Trainer ---
        gen = CoreGANGenerator(
            time_steps=cfg.context_len,
            in_channels=cfg.in_channels,
            H=cfg.H_out,
            W=cfg.W_out,
            out_channels=1,
        )
        disc = CoreGANDiscriminator(in_channels=cfg.in_channels)

        coregan_cfg = CoreGANConfig.from_global_cfg(cfg)
        # make sure it uses the same device
        coregan_cfg.device = device
        # optionally put results into your existing dirs
        coregan_cfg.save_dir = cfg.results_dir

        trainer = CoreGANTrainer(gen, disc, cfg=coregan_cfg)

        print("Starting CoreGAN training...")
        metrics, test_mse = trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            test_loader=test_loader,
            checkpoint_path=cfg.model_ckpt,  # same pattern as others
        )
        print("CoreGAN training finished.")
        if test_mse is not None:
            print(f"CoreGAN Test MSE: {test_mse:.6f}")
        return  # done




    # device = cfg.device
    # if not torch.cuda.is_available():
    #     device = "cpu"
    # print(f"Using device: {device}")
    #
    # print("Preparing dataloaders (this will generate dataset if missing)...")
    # # train_loader, val_loader, _, scaler, train_idx, val_idx, test_idx = prepare_dataloaders()
    # train_loader, val_loader, test_loader, scaler, train_idx, val_idx, test_idx = prepare_dataloaders()

    # n_train = len(train_idx)
    # n_val = len(val_idx)
    # print(f"Train windows: {n_train}, Val windows: {n_val}")
    # print(f"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}")

    # model = UNet(
    #     in_channels=cfg.in_channels,
    #     out_channels=1,
    #     out_size=(cfg.H_out, cfg.W_out),  # enforce 15x24 output
    # ).to(device)
    # model = CNNGRUForecaster(
    #     in_channels=1,
    #     feature_dim=256,
    #     gru_hidden_dim=256,
    #     gru_layers=1,
    #     horizon_size=(cfg.H_out, cfg.W_out)
    # ).to(device)
    model = build_model_from_cfg(cfg).to(device)
    print(model.__class__.__name__)
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)
    criterion = nn.MSELoss()

    os.makedirs(cfg.checkpoint_dir, exist_ok=True)
    best_val_loss = float("inf")
    epochs_no_improve = 0

    patience = getattr(cfg, "early_stop_patience", None)
    min_delta = getattr(cfg, "early_stop_min_delta", 0.0)
    use_early = getattr(cfg, "early_stop", False) and patience is not None

    for epoch in range(1, cfg.num_epochs + 1):
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)
        val_loss = evaluate(model, val_loader, criterion, device)

        print(
            f"Epoch [{epoch}/{cfg.num_epochs}] "
            f"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}"
        )

        # check improvement (smaller is better)
        if val_loss < best_val_loss - min_delta:
            best_val_loss = val_loss
            epochs_no_improve = 0

            torch.save(
                {
                    "model_state_dict": model.state_dict(),
                    "best_val_loss": best_val_loss,
                    "epoch": epoch,
                },
                cfg.model_ckpt,
            )
            print(f"  -> Saved best model to {cfg.model_ckpt}")
        else:
            epochs_no_improve += 1

        # early stopping condition
        if use_early and epochs_no_improve >= patience:
            print(
                f"Early stopping triggered at epoch {epoch}. "
                f"No improvement in validation loss for {patience} consecutive epochs."
            )
            break


if __name__ == "__main__":
    main()
